{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0fd28c",
   "metadata": {},
   "source": [
    "# Prediction of Nighttime NO2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b01399",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260b76d",
   "metadata": {},
   "source": [
    "### Names and Acronyms\n",
    "1) ASDC: [Atmosperhic Science Data Center](https://asdc.larc.nasa.gov/about)\n",
    "1) PGN (Pandora): [Pandonia Global Network](https://www.pandonia-global-network.org/) / [Pandora](https://pandora.gsfc.nasa.gov/About/)\n",
    "    - **NOTE**: NASA's portion of the PGN is known as Pandora.  Within the scope of this notebook, Pandora and PGN may be used interchangably as this project will only use NASAs PGN site data.\n",
    "1) TEMPO: [Troposoperic Emissions: Monitoring of Pollution](https://science.nasa.gov/mission/tempo/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4999c",
   "metadata": {},
   "source": [
    "### Resources\n",
    "1) ASDC Data Processing Tool (Version 1)\n",
    "    - This notebook was published by the ASDC and provides examples of how to correctly load and use Pandora and TEMPO data.\n",
    "    - https://github.com/nasa/ASDC_Data_and_User_Services/blob/main/TEMPO/additional_drafts/ASDC_Data_Processing_ML_v1.2.ipynb\n",
    "1) PGN Station Map\n",
    "    - A map showing the location of all PGN groundsites.\n",
    "    - https://blickm.hetzner.pandonia-global-network.org/livemaps/pgn_stationsmap.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c7064",
   "metadata": {},
   "source": [
    "This notebook borrows heavily from and extens the functionality of the NASA, ASDC Data and User Servicies notebook found here:\n",
    "\n",
    "https://github.com/nasa/ASDC_Data_and_User_Services/blob/main/TEMPO/additional_drafts/ASDC_Data_Processing_ML_v1.2.ipynb\n",
    "\n",
    "This notebook intends to test the hypothesis that a model can be built with Pandora which can predict nightitme NO<sub>2</sub> and that that model can be applied to TEMPO daytime measurments to predict NO<sub>2</sub> for any location covered by TEMPO.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7cdc1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1657c",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "There are many tools available such as [poetry](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://python-poetry.org/&ved=2ahUKEwjr9aLgna6QAxX5EVkFHVsNBMUQFnoECBsQAQ&usg=AOvVaw3Jp8q7OO7XkcY8Tq4tDe30) and [uv](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://docs.astral.sh/uv/&ved=2ahUKEwiP9aXVna6QAxVyF1kFHeyTNGYQFnoECAsQAQ&usg=AOvVaw2VJVt0jrah2S9tIgdc1yRc) that simplify and speed up environment setup.  For simplicity, this guide only covers the method built into the python standard library.\n",
    "1) Install [Python 3.11](https://www.python.org/downloads/) (or higher)\n",
    "1) (Recomended) Create a virtual environment (learn more [here](https://docs.python.org/3/library/venv.html))\n",
    "1) Install the required packages using the following command.<br>`% pip install pyproject.toml`\n",
    "1) Select the newly created kernal in your notebook.\n",
    "    - NOTE: this varies slightly between notebook tools, but in almost all tools you will be prompted to select a kernal upon running a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c5de3",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79c24beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import earthaccess\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571cbfbc",
   "metadata": {},
   "source": [
    "### Data Access\n",
    "In order to access data, you will need an Earthdata Login account.  If you do not have an Earthdata Login account, you can create one here:<br>\n",
    "https://urs.earthdata.nasa.gov/\n",
    "\n",
    "The earthaccess module allows you to authenticate.  Multilple login options exist for providing your credentials, you can read more on options here:<br>\n",
    "https://pypi.org/project/earthaccess/<br>\n",
    "By unless another option is configured, you will be prompted by your notebook to enter your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a082e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x20d80072b10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa5d17",
   "metadata": {},
   "source": [
    "Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae862668",
   "metadata": {},
   "outputs": [],
   "source": [
    "PGN_DATA_DIR = Path('pgn-data')\n",
    "PGN_DATA_DIR.mkdir(mode=0o777, parents=True, exist_ok=True)\n",
    "PGN_DATA_PATH = PGN_DATA_DIR.joinpath('pgn-data.csv')\n",
    "TEMPO_DATA_DIR = Path('tempo-data')\n",
    "TEMPO_DATA_DIR.mkdir(mode=0o777, parents=True, exist_ok=True)\n",
    "TEMPO_DATA_PATH = TEMPO_DATA_DIR.joinpath('tempo-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d02eaa",
   "metadata": {},
   "source": [
    "## 1. Data Prepairation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114510e5",
   "metadata": {},
   "source": [
    "### 1.1. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3f556",
   "metadata": {},
   "source": [
    "#### 1.1.1. Define Download Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13d742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2023, 7, 1)\n",
    "end_date = datetime(2023, 7, 31)\n",
    "temporal_range = [start_date, end_date]\n",
    "spatial_range = []\n",
    "\n",
    "sites = ['BronxNY', 'BuffaloNY', 'QueensNY']\n",
    "sites_url = \"https://data.pandonia-global-network.org\"\n",
    "\n",
    "# settings for various types of pgn files\n",
    "all_pgn_formats = {\n",
    "    \"rnvh3p1-8.txt\": {\n",
    "        'no2_quality_flag_index': 52,\n",
    "        'valid_quality_flags': [0, 10],\n",
    "        'column_index': 61,\n",
    "        'column_unc_index': 62,\n",
    "    },\n",
    "    \"rnvm2p1-8.txt\": {\n",
    "        'no2_quality_flag_index': 35,\n",
    "        'valid_quality_flags': [0, 1, 10, 11],\n",
    "        'column_index': 38,\n",
    "        'column_unc_index': 39,\n",
    "    }\n",
    "}\n",
    "\n",
    "# formats to process\n",
    "pgn_formats = {\n",
    "    \"rnvh3p1-8.txt\": all_pgn_formats[\"rnvh3p1-8.txt\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640f721",
   "metadata": {},
   "source": [
    "#### 1.1.1. Download Pandora data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d329d",
   "metadata": {},
   "source": [
    "Get sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56e73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_links(url: str):\n",
    "    \"\"\"\n",
    "    An tool for getting all PGN links from a PGN data webpage (https://data.hetzner.pandonia-global-network.org/)\n",
    "\n",
    "    ARGS:\n",
    "        url (str): The URL of the page to extract links form\n",
    "    \"\"\"\n",
    "    things_to_remove = [\n",
    "        '<span class=\"name\">',\n",
    "        '</span>',\n",
    "        '/</span>'\n",
    "    ]\n",
    "\n",
    "    response = requests.get(url)\n",
    "    assert response.status_code==200, f\"Download failed with code {response.status_code}\"\n",
    "    \n",
    "    # get item name lines\n",
    "    names = [l.strip() for l in response.text.splitlines()]\n",
    "    names = [l for l in names if l.startswith('<span class=\"name\">')]\n",
    "\n",
    "    # get item names from name lines\n",
    "    for thing_to_remove in things_to_remove:\n",
    "        names = [l.replace(thing_to_remove, '') for l in names]\n",
    "        names = [l.rstrip('/') for l in names]\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9d603",
   "metadata": {},
   "source": [
    "Build file URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ca2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting File URLs\n",
      "Site 1 of 3: BronxNY\n",
      "\tInstrument 1 of 2: Pandora147s1\n",
      "\tInstrument 2 of 2: Pandora180s1\n",
      "Site 2 of 3: BuffaloNY\n",
      "\tInstrument 1 of 1: Pandora206s1\n",
      "Site 3 of 3: QueensNY\n",
      "\tInstrument 1 of 1: Pandora55s1\n",
      "File URLs:\n",
      "\thttps://data.pandonia-global-network.org/BronxNY/Pandora147s1/L2/Pandora147s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "\thttps://data.pandonia-global-network.org/BronxNY/Pandora180s1/L2/Pandora180s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "\thttps://data.pandonia-global-network.org/BuffaloNY/Pandora206s1/L2/Pandora206s1_BuffaloNY_L2_rnvh3p1-8.txt\n",
      "\thttps://data.pandonia-global-network.org/QueensNY/Pandora55s1/L2/Pandora55s1_QueensNY_L2_rnvh3p1-8.txt\n"
     ]
    }
   ],
   "source": [
    "# get file URLs\n",
    "print(\"Getting File URLs\")\n",
    "pgn_urls: list[str] = []\n",
    "for i, site in enumerate(sites):\n",
    "    site_url = f\"{sites_url}/{site}\"\n",
    "    instruments = get_page_links(site_url)\n",
    "    print(f\"Site {i+1} of {len(sites)}:\", site)\n",
    "    for j, instrument in enumerate(instruments):\n",
    "        print(f\"\\tInstrument {j+1} of {len(instruments)}:\", instrument)\n",
    "        for file_suffix in pgn_formats.keys():\n",
    "            file_url = f\"{site_url}/{instrument}/L2/{instrument}_{site}_L2_{file_suffix}\"\n",
    "            # verify file exists\n",
    "            if not requests.head(file_url, allow_redirects=True).ok:\n",
    "                print(f\"\\tFile does not exist (this may not be an issue): {file_url}\")\n",
    "                continue\n",
    "            pgn_urls.append(file_url)\n",
    "\n",
    "print(\"File URLs:\")\n",
    "for pgn_url in pgn_urls:\n",
    "    print(f\"\\t{pgn_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c3a58",
   "metadata": {},
   "source": [
    "Download files (if not already downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4dc28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pgn files to pgn-data\n",
      "File 1 of 4 exists and will not be downloaded: Pandora147s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "File 2 of 4 exists and will not be downloaded: Pandora180s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "File 3 of 4 exists and will not be downloaded: Pandora206s1_BuffaloNY_L2_rnvh3p1-8.txt\n",
      "File 4 of 4 exists and will not be downloaded: Pandora55s1_QueensNY_L2_rnvh3p1-8.txt\n",
      "Files downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download Files\n",
    "pgn_paths: list[Path] = []\n",
    "print(f\"Downloading pgn files to {PGN_DATA_DIR}\")\n",
    "for i, pgn_url in enumerate(pgn_urls):\n",
    "    file_name = Path(pgn_url).name\n",
    "    file_path = PGN_DATA_DIR.joinpath(file_name)\n",
    "    if file_path.exists():\n",
    "        print(f\"File {i+1} of {len(pgn_urls)} exists and will not be downloaded: {file_name}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\tDownloading file {i+1} of {len(pgn_urls)}: {file_name}\")\n",
    "        response = requests.get(pgn_url)\n",
    "        file_path.write_bytes(response.content)\n",
    "\n",
    "    pgn_paths.append(file_path)\n",
    "print(\"Files downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570190e9",
   "metadata": {},
   "source": [
    "Build a datafram of all PGN data for columns with valid quality flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a5d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGN Loading Started\n",
      "Loading file 1 of 4: Pandora147s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "\tWARNING: No valid observations found (NO2 quality flag of 0 or 10)\n",
      "Loading file 2 of 4: Pandora180s1_BronxNY_L2_rnvh3p1-8.txt\n",
      "\tValid Observations: 3208\n",
      "Loading file 3 of 4: Pandora206s1_BuffaloNY_L2_rnvh3p1-8.txt\n",
      "\tValid Observations: 4894\n",
      "Loading file 4 of 4: Pandora55s1_QueensNY_L2_rnvh3p1-8.txt\n",
      "\tValid Observations: 16168\n",
      "PGN Loading Complete, found (24270, 6) valid observations.\n",
      "Writing to pgn-data\\pgn-data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Column</th>\n",
       "      <th>Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-01 12:09:22.300</td>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "      <td>BronxNY</td>\n",
       "      <td>1.825732e+16</td>\n",
       "      <td>1.744915e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-01 12:19:59.400</td>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "      <td>BronxNY</td>\n",
       "      <td>2.381636e+16</td>\n",
       "      <td>2.086551e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-01 12:43:43.400</td>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "      <td>BronxNY</td>\n",
       "      <td>2.643900e+16</td>\n",
       "      <td>1.995075e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-01 13:39:43.200</td>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "      <td>BronxNY</td>\n",
       "      <td>3.037989e+16</td>\n",
       "      <td>2.163033e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-01 13:57:10.500</td>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "      <td>BronxNY</td>\n",
       "      <td>2.223254e+16</td>\n",
       "      <td>1.486084e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Latitude  Longitude Location        Column  \\\n",
       "0 2023-07-01 12:09:22.300   40.8679   -73.8781  BronxNY  1.825732e+16   \n",
       "1 2023-07-01 12:19:59.400   40.8679   -73.8781  BronxNY  2.381636e+16   \n",
       "2 2023-07-01 12:43:43.400   40.8679   -73.8781  BronxNY  2.643900e+16   \n",
       "3 2023-07-01 13:39:43.200   40.8679   -73.8781  BronxNY  3.037989e+16   \n",
       "4 2023-07-01 13:57:10.500   40.8679   -73.8781  BronxNY  2.223254e+16   \n",
       "\n",
       "    Uncertainty  \n",
       "0  1.744915e+14  \n",
       "1  2.086551e+14  \n",
       "2  1.995075e+14  \n",
       "3  2.163033e+14  \n",
       "4  1.486084e+14  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PGN format settings (these should not change)\n",
    "pgn_section_delim = f\"{'-'*87}\\n\"\n",
    "header_delim = \": \"\n",
    "pgn_loc_key = \"Short location name\"\n",
    "pgn_lat_key = \"Location latitude [deg]\"\n",
    "pgn_lon_key = \"Location longitude [deg]\"\n",
    "# Avogadro constant divided by 10000\n",
    "no2_scale = 6.02214076E+19\n",
    "\n",
    "# build the final dataset\n",
    "pgn_data = pd.DataFrame()\n",
    "print(\"PGN Loading Started\")\n",
    "for i, pgn_path in enumerate(pgn_paths):\n",
    "    print(f\"Loading file {i+1} of {len(pgn_paths)}: {pgn_path.name}\")\n",
    "\n",
    "    # get file format indicies\n",
    "    file_suffix = pgn_path.name.split('_')[-1]\n",
    "    file_data = pgn_formats.get(file_suffix)\n",
    "    if file_data is None:\n",
    "      raise Exception(f\"Invalid suffix for {pgn_path}, handled suffixes:\", pgn_formats)\n",
    "    no2_quality_flag_index = file_data['no2_quality_flag_index']\n",
    "    valid_quality_flags = file_data['valid_quality_flags']\n",
    "    column_index = file_data['column_index']\n",
    "    column_unc_index = file_data['column_unc_index']\n",
    "\n",
    "    # get file sections as lines\n",
    "    text = pgn_path.read_text()\n",
    "    metadata_text, column_text, data_text = text.split(pgn_section_delim)\n",
    "    metadata_lines = metadata_text.splitlines()\n",
    "    column_lines = column_text.splitlines()\n",
    "    data_lines = data_text.splitlines()\n",
    "\n",
    "    # get metadata\n",
    "    metadata = {}\n",
    "    for line in metadata_lines:\n",
    "        key, value = line.split(header_delim)\n",
    "        metadata[key] = value\n",
    "\n",
    "    # get data\n",
    "    rows = []\n",
    "    for line in data_lines:\n",
    "      values = line.split()\n",
    "\n",
    "      # ignore if timestamp is not between start and end time\n",
    "      timestamp = datetime.fromisoformat(values[0]).replace(tzinfo=None)\n",
    "      if not (start_date <= timestamp):\n",
    "        continue\n",
    "\n",
    "      # ignore row if quality is not between 0 and 10\n",
    "      no2_quality_flag = int(values[no2_quality_flag_index])\n",
    "      if no2_quality_flag not in valid_quality_flags:\n",
    "        continue\n",
    "      \n",
    "      # Nitrogen dioxide tropospheric vertical column amount [moles per square meter]\n",
    "      column = float(values[61])\n",
    "      # Independent uncertainty of nitrogen dioxide tropospheric vertical column amount [moles per square meter]\n",
    "      column_unc = float(values[62])\n",
    "\n",
    "      lat = float(metadata[pgn_lat_key])\n",
    "      lon = float(metadata[pgn_lon_key])\n",
    "      loc = metadata[pgn_loc_key]\n",
    "      row = {\n",
    "         'Timestamp': timestamp, \n",
    "         'Latitude': lat, \n",
    "         'Longitude': lon, \n",
    "         'Location': loc, \n",
    "         'Column': column*no2_scale, \n",
    "         'Uncertainty': column_unc*no2_scale\n",
    "      }\n",
    "      rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not rows:\n",
    "      print(\"\\tWARNING: No valid observations found (NO2 quality flag of 0 or 10)\")\n",
    "    else:\n",
    "      print(f\"\\tValid Observations: {len(rows)}\")\n",
    "    pgn_data = pd.concat([pgn_data, df])\n",
    "print(f\"PGN Loading Complete, found {pgn_data.shape} valid observations.\")\n",
    "print(\"Writing to\", PGN_DATA_PATH)\n",
    "pgn_data.to_csv(PGN_DATA_PATH, index=False)\n",
    "pgn_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfaa0d",
   "metadata": {},
   "source": [
    "Get latitudes and longitudes (for use with TEMPO download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14cfaa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BronxNY</th>\n",
       "      <td>40.8679</td>\n",
       "      <td>-73.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BuffaloNY</th>\n",
       "      <td>43.0015</td>\n",
       "      <td>-78.7869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QueensNY</th>\n",
       "      <td>40.7361</td>\n",
       "      <td>-73.8215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Latitude  Longitude\n",
       "Location                      \n",
       "BronxNY     40.8679   -73.8781\n",
       "BuffaloNY   43.0015   -78.7869\n",
       "QueensNY    40.7361   -73.8215"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgn_sites_df = pgn_data[['Location', 'Latitude', 'Longitude']].drop_duplicates().set_index('Location')\n",
    "pgn_sites_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef878a3",
   "metadata": {},
   "source": [
    "#### 1.1.1 Download TEMPO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a83af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123,)\n",
      "(123, 2048)\n",
      "(123, 2048)\n",
      "(123, 2048)\n",
      "(123, 2048)\n",
      "[[59.290962 59.24963  59.20839  ... 17.34152  17.326826 17.312134]\n",
      " [59.277916 59.236637 59.195454 ... 17.34037  17.325676 17.310984]\n",
      " [59.26651  59.225285 59.18415  ... 17.339794 17.325102 17.310411]\n",
      " ...\n",
      " [58.302814 58.264565 58.228058 ... 17.289572 17.274948 17.260324]\n",
      " [58.295998 58.258343 58.220425 ... 17.28848  17.273857 17.259233]\n",
      " [58.292873 58.25554  58.21623  ... 17.289175 17.274553 17.25993 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_20532\\1352611185.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  no2_col = np.array(col_var)\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_20532\\1352611185.py:7: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  no2_unc = np.array(unc_var)\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_20532\\1352611185.py:15: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  lat = np.array(geo.variables['latitude']) # this reads variable latitude from geo (geolocation group, /geolocation) into a numpy array\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_20532\\1352611185.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  lon = np.array(geo.variables['longitude']) # this reads variable longitude from geo (geolocation group, /geolocation) into a numpy array\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_20532\\1352611185.py:18: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  time = np.array(geo.variables['time'] )# this reads variable longitude from geo (geolocation group, /geolocation) into a numpy array\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32408bb7",
   "metadata": {},
   "source": [
    "### 1.2. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ea48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bde00571",
   "metadata": {},
   "source": [
    "### 1.3. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f1694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d08698",
   "metadata": {},
   "source": [
    "### 1.4. Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba6d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08645d08",
   "metadata": {},
   "source": [
    "## 2. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819fdd0",
   "metadata": {},
   "source": [
    "### 2.1 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d32961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac2ff45a",
   "metadata": {},
   "source": [
    "### 2.2 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77b91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b7fe43",
   "metadata": {},
   "source": [
    "### 2.3. Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd37ff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
